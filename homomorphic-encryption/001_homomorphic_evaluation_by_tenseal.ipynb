{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to implement our first encrypted machine learning evaluation using TenSEAL! We will use the Tox21 dataset (released by NIH and EPA), which provides different molecules (each is a 1024-bit vector), along with a label vector of 12 classes, representing different toxic effects.\n",
    "\n",
    "The goal is to first train a model on plain data using PyTorch, then doing encrypted evaluation on the entire test set using TenSEAL. You can later see that we get approximately the same results doing the evaluation on plain or encrypted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6cb005c738>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tenseal as ts\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "th.manual_seed(73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tox21 dataset was downloaded using deepchem, and prepared as torch tensors for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = th.load(\"data/train_X.pt\")\n",
    "train_y = th.load(\"data/train_y.pt\")\n",
    "test_X = th.load(\"data/test_X.pt\")\n",
    "test_y = th.load(\"data/test_y.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some data loaders for our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "train_dataset = TensorDataset(train_X, train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64)\n",
    "# Test dataset\n",
    "test_dataset = TensorDataset(test_X, test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a PyTorch model, consisting of 2 linear layers, and a square activation function between them. The choice of the square activation is not random. We can choose to approximate non-linear activation functions such as sigmoid, which may require a higher polynomial (thus bigger homomorphic encryption parameters). For simplicity, we only use the square activation, which requires a single multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 12)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = out * out\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion, epochs):\n",
    "    losses = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        model.eval()\n",
    "        print('Train Epoch: {:2d}   Avg Loss: {:.6f}'.format(epoch, th.mean(th.tensor(losses))))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:  1   Avg Loss: 0.681649\n",
      "Train Epoch:  2   Avg Loss: 0.621732\n",
      "Train Epoch:  3   Avg Loss: 0.550540\n",
      "Train Epoch:  4   Avg Loss: 0.500284\n",
      "Train Epoch:  5   Avg Loss: 0.465285\n",
      "Train Epoch:  6   Avg Loss: 0.439468\n",
      "Train Epoch:  7   Avg Loss: 0.419374\n",
      "Train Epoch:  8   Avg Loss: 0.403043\n",
      "Train Epoch:  9   Avg Loss: 0.389307\n",
      "Train Epoch: 10   Avg Loss: 0.377432\n",
      "Train Epoch: 11   Avg Loss: 0.366937\n",
      "Train Epoch: 12   Avg Loss: 0.357497\n",
      "Train Epoch: 13   Avg Loss: 0.348892\n",
      "Train Epoch: 14   Avg Loss: 0.340964\n",
      "Train Epoch: 15   Avg Loss: 0.333602\n",
      "Train Epoch: 16   Avg Loss: 0.326724\n",
      "Train Epoch: 17   Avg Loss: 0.320269\n",
      "Train Epoch: 18   Avg Loss: 0.314190\n",
      "Train Epoch: 19   Avg Loss: 0.308450\n",
      "Train Epoch: 20   Avg Loss: 0.303017\n",
      "Train Epoch: 21   Avg Loss: 0.297866\n",
      "Train Epoch: 22   Avg Loss: 0.292975\n",
      "Train Epoch: 23   Avg Loss: 0.288323\n",
      "Train Epoch: 24   Avg Loss: 0.283892\n",
      "Train Epoch: 25   Avg Loss: 0.279668\n",
      "Train Epoch: 26   Avg Loss: 0.275634\n",
      "Train Epoch: 27   Avg Loss: 0.271778\n",
      "Train Epoch: 28   Avg Loss: 0.268086\n",
      "Train Epoch: 29   Avg Loss: 0.264548\n",
      "Train Epoch: 30   Avg Loss: 0.261154\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "#device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n",
    "\n",
    "model = train(model, device, train_loader, optimizer, criterion, 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.92\n"
     ]
    }
   ],
   "source": [
    "def compute_labels(out):\n",
    "    out = th.sigmoid(out)\n",
    "    return (out >= 0.5).int()\n",
    "\n",
    "\n",
    "# compute accuracy using hamming loss\n",
    "def accuracy(output, target):\n",
    "    # convert to labels\n",
    "    out = compute_labels(output)\n",
    "    # flatten and compute hamming loss\n",
    "    flat_out = out.flatten()\n",
    "    flat_target = target.flatten()\n",
    "    incorrect = th.logical_xor(flat_out, flat_target).sum().item()\n",
    "    hamming_loss = incorrect / len(flat_out)\n",
    "    return 1 - hamming_loss\n",
    "\n",
    "\n",
    "print(\"Accuracy on test set: {:.2f}\".format(accuracy(model(test_X), test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a PyTorch-like model, but which uses TenSEAL operations. During initialization, we fetch and store weights from PyTorch layers. The forward method will then use the stored weights to perform linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HEModel:\n",
    "    def __init__(self, fc1, fc2):\n",
    "        self.fc1_weight = fc1.weight.t().tolist()\n",
    "        self.fc1_bias = fc1.bias.tolist()\n",
    "        self.fc2_weight = fc2.weight.t().tolist()\n",
    "        self.fc2_bias = fc2.bias.tolist()\n",
    "        \n",
    "    def forward(self, encrypted_vec):\n",
    "        # first fc layer + square activation function\n",
    "        encrypted_vec = encrypted_vec.mm(self.fc1_weight) + self.fc1_bias\n",
    "        encrypted_vec *= encrypted_vec\n",
    "        # second fc layer\n",
    "        encrypted_vec = encrypted_vec.mm(self.fc2_weight) + self.fc2_bias\n",
    "        return encrypted_vec\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have previously discussed some intuitions on how to choose the encryption parameters, and now we have to put them into practice. Our model evaluation requires 3 multiplications, one for the square activation, and two for the matmul operation. So we ultimately need 3 `bits_scale` at the middle of our `coeff_mod_bit_sizes`. Now the choice of `bits_scale`, which impacts the precision of the fractional part, so we can try different values (so different precisions) so that we don't impact accuracy by much. The last coefficient modulus should be higher than the `bits_scale` and the difference between them (5 here) impacts the precision of the integer part. Since we are manipulating small numbers here, 5 should be enough. After choosing those parameters, we need to find the appropriate polynomial modulus degree to use, to guarantee 128-bits security. You can start with small power of two (e.g. 4096) and go higher, till TenSEAL doesn't throw an error. If you are more curious, you can look-up the bounds for those parameters and choose the right one directly. It is also important to choose the polynomial modulus degree that allows us to put all our elements into a ciphertext. Here, we need to put 1024 values, and anything above 2048 should make it, but only 8192 (and above) meet the security requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "bits_scale = 25\n",
    "coeff_mod_bit_sizes = [30, bits_scale, bits_scale, bits_scale, 30]\n",
    "polynomial_modulus_degree = 8192\n",
    "\n",
    "# Create context\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS, polynomial_modulus_degree, coeff_mod_bit_sizes=coeff_mod_bit_sizes)\n",
    "# Set global scale\n",
    "context.global_scale = 2 ** bits_scale\n",
    "# Generate galois keys required for matmul in ckks_vector\n",
    "context.generate_galois_keys()\n",
    "\n",
    "he_model = HEModel(model.fc1, model.fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encrypted evaluation can now be done on the entire test set, one by one. We start by encrypting the vector, then do the encrypted evaluation, and finally decrypt the result. If this was implemented using two parties, then the encrypted vector will be sent over for remote evaluation, and the encrypted result will be sent back for decryption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many labels in the encrypted evaluation are the same as in the plain evaluation?\n",
    "match = 0\n",
    "he_outs = []\n",
    "for data, _ in test_loader:\n",
    "    # remove batch axis, we only need a flat vector\n",
    "    vec = data.flatten()\n",
    "    # encryption\n",
    "    encrypted_vec = ts.ckks_vector(context, vec)\n",
    "    # encrypted evaluation\n",
    "    encrypted_out = he_model(encrypted_vec)\n",
    "    # decryption\n",
    "    he_out = th.tensor(encrypted_out.decrypt())\n",
    "    he_outs.append(he_out.tolist())\n",
    "    out = model(data)\n",
    "    # how many labels match\n",
    "    he_labels = compute_labels(he_out)\n",
    "    plain_labels = compute_labels(out)\n",
    "    match += (he_labels == plain_labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on test set (encrypted evaluation): {:.2f}\".format(accuracy(th.tensor(he_outs), test_y)))\n",
    "print(\"Encrypted evaluation matched {:.1f}% of the labels from the plain evaluation\".format(\n",
    "    match / (12 * len(test_loader)) * 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
